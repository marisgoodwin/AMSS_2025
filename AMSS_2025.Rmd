---
title: "AMSS_2025"
author: "Maris Goodwin"
date: "2024-12-29"
output: html_document
---
This is the analysis for my AMMS 2025 presentation.

The abstract is here: 

Title: Understanding seasonality of fish biodiversity using eDNA metabarcoding in Kachemak
Bay, Alaska
Authors: Maris R. Goodwin, Zack Gold, Jennifer L. Tusten, Jessica R. Glass
As global climate change rapidly impacts Arctic and subarctic marine ecosystems,
scientists need tools that will rigorously quantify changes in biological communities. Arctic
biodiversity monitoring is essential as glacial estuaries face recession, where the dynamic
convergence of freshwater and marine environments has historically supported diverse
ecological communities. Genomic sequencing tools such as environmental DNA (eDNA)
metabarcoding complement conventional fisheries approaches (e.g., netting) by providing in-
depth, rapid, and non-invasive assessments of species composition. We implemented eDNA
metabarcoding to assess its utility as an ecological monitoring tool in 5 estuarine sites in
Kachemak Bay, Alaska with varying degrees of glacial coverage (0 â€“ 60%). We analyzed
(n=100) eDNA samples from April and September 2022 in Kachemak Bay to tease apart
seasonal and spatial patterns in fish diversity and to assess the extent to which environmental
variables drive community composition. Results suggest a stronger influence of seasonal drivers
on fish biodiversity than spatial drivers. Detections of fish taxa were higher using eDNA than
conventional beach seining. The results of this study will build on existing baseline data to
document changes in a region heavily impacted by climate change.

A few things to note: 

All (seine and eDNA) data will be standardized from 0 to 1 to provide a semiquantitative value for comparison. In this transformation, the abundance values are first standardized by species maximum standardization, and then by sample total standardization, and by convention multiplied by 100 (here we will have values from 0 to 1). Essentially, each element is divided by its column maximum and then divided by the row total. Bray and Curtis (1957) employed a double standardization before ordination. In their study, tree species were measured on different scales than were shrubs and herbs (density and basal area for trees, frequency for herbs and shrubs), so that a species maximum standardization achieved a common scale. Their rationalization for the subsequent sample total standardization was that not all samples had the same number of measurements, and that the stand total standardizations achieved a more uniform basis for comparison. The environmental variables will be standardized as follows: 
salinity-
temperature- 
DO- 
turbidity-


# First we will load the necessary libraries for this analysis.
```{r load libs}
# Install and load necessary packages
# if (!requireNamespace("vegan", quietly = TRUE)) install.packages("vegan")
 if (!requireNamespace("ecodist", quietly = TRUE)) install.packages("ecodist")
# if (!requireNamespace("ggplot2", quietly = TRUE)) install.packages("ggplot2")
# if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")

library(vegan)
library(ecodist)
library(ggplot2)
library(dplyr)
library(qiime2R)
library(phyloseq)
```

# Next we will load the data and take a look at it. 
```{r load data}
# Load the seine data including fish community data and taxa classification
seine <- read.csv("/Users/marisgoodwin/Documents/GITHUB/AMSS_2025/inputs/seine/2019_2020_2021_2022_Fish_Community_Data.csv")
seine_taxa <- read.csv("/Users/marisgoodwin/Documents/GITHUB/AMSS_2025/inputs/seine/fish_taxa_classification.csv")

# load in environmental data, this is also seine metadata
env <- read.csv("/Users/marisgoodwin/Documents/GITHUB/AMSS_2025/inputs/environmental/JNKB_20212022_Point_Sampling.csv")

# Load in the data from the L20230323_0629C Azenta run. This has samples from April and September 2022 in Kachemak Bay. 
edna_groups <- read.csv("/Users/marisgoodwin/Documents/GITHUB/AMSS_2025/inputs/eDNA/taxon_groups.csv")
edna_tax <- read.csv("/Users/marisgoodwin/Documents/GITHUB/AMSS_2025/inputs/eDNA/taxonomy_collapsed.csv")
method = "dada2-pe"
filtering = "unfiltered"
edna_table <- read_qza("/Users/marisgoodwin/Documents/GITHUB/AMSS_2025/inputs/eDNA/table.qza",method,filtering)

edna_meta <- read.csv("/Users/marisgoodwin/Documents/GITHUB/AMSS_2025/inputs/eDNA/Samples_kb_jn_samples.csv")
```
```{r reformatting}
# add in some reformatting of the data
edna_meta <- edna_meta %>%
  mutate(
    SamplingDate = mdy(SamplingDate),
    SamplingDate = format(SamplingDate, format = "%m/%d/%Y"),
    sample.name.library.prep = if_else(str_detect(sample.name.library.prep, "NC$"),
                                        str_replace(sample.name.library.prep, "NC$", "nc"),
                                        sample.name.library.prep)
  )
# Clean invalid characters and then apply the trimming and replacing operations
edna_meta <- edna_meta %>%
  mutate(Region = iconv(Region, from = "UTF-8", to = "UTF-8", sub = ""),  # Remove invalid characters
         Region = str_trim(Region),         # Remove trailing spaces
         Region = str_replace_all(Region, "Kachemak Bay", "Kachemak Bay"))  # 

month_mapping <- c(
  "Jan" = "January", "February" = "February", "Feb" = "February",
  "Mar" = "March", "March" = "March", "Apr" = "April", "April" = "April",
  "May" = "May", "Jun" = "June", "June" = "June", "Jul" = "July",
  "July" = "July", "Aug" = "August", "August" = "August",
  "Sep" = "September", "September" = "September"
)

# Clean and standardize the SamplingMonth column
edna_meta <- edna_meta %>%
  mutate(SamplingMonth = str_trim(SamplingMonth),  # Remove leading/trailing spaces
         SamplingMonth = dplyr::recode(SamplingMonth, !!!month_mapping))  # Recode to consistent names

env <- env %>%
  mutate(SamplingDate = mdy(SamplingDate),
         SamplingDate = format(SamplingDate, format = "%m/%d/%Y"))
seine <- seine %>%
  mutate(SamplingDate = mdy(SamplingDate),
         SamplingDate = format(SamplingDate, format = "%m/%d/%Y"))
```

# Now we are going to get only the data we are interested in for this analysis which is the fish community data and the environmental data from Kachemak Bay in 2022 April and September. 
```{r kb data}
# subset the edna meta by the samples from Kachemak Bay in 2022 April and September
kb_edna_meta <- edna_meta %>%
  filter(SamplingYear.x == 2022, SamplingMonth %in% c("April", "September"), Region == "Kachemak Bay")

# now do the same for the seine data
kb_seine <- seine %>%
  filter(SamplingYear == 2022, SamplingPeriod %in% c("1", "6"), Region == "kb")
# now for the environmental data
kb_env <- env %>%
  filter(SamplingYear == 2022, SamplingMonth %in% c("April", "September"), region == "kb")
```

# Now we are going to standardize the seine data. 
```{r standardize}
# first let's create a site by species matrix from the kb_seine data, the count is in the column "Count", the species is in the column "ScientificName," and we will make a unique identifier for each sample in the column "SampleID" this will combine the SiteAcronym and the SamplingPeriod

# create the unique identifier
kb_seine$SampleID <- paste(kb_seine$SiteAcronym, kb_seine$SamplingPeriod, sep = "_")

# first we need to aggregate 
kb_seine <- kb_seine %>%
  group_by(SampleID, ScientificName) %>%
  summarise(Count = sum(Count)) %>% 
  ungroup()
# create the site by species matrix
site_by_species <- kb_seine %>%
  dplyr::select(SampleID, ScientificName, Count) %>%
  spread(key = ScientificName, value = Count, fill = 0)
# now make the rownames the SampleID and remove the column 
rownames(site_by_species) <- site_by_species$SampleID
site_by_species <- site_by_species[, -1]
# now we want to standardize the data with a wisconsin double standardization
wisconsin <- wisconsin(site_by_species) 

# this now gives us a standardized site by species matrix with the proportion of each species in each sample from 0 to 1 

# now we want to do the same for the environmental data, let's aggregate by site acronym and sampling date, we will take the mean of the environmental variables, if there are multiple samples for a site and date 
kb_env <- kb_env %>%
  group_by(site_id,SamplingMonth) %>%
  summarise(Salinity = mean(Salinity, na.rm = TRUE),
            Temperature = mean(Temperature, na.rm = TRUE),
            DissolvedOxygen = mean(DissolvedOxygen, na.rm = TRUE),
            #for turbidity we have Turbidity_rep1 and Turbidity_rep2 and Turbidity_rep3 we will take the mean of these
            Turbidity = mean(c(Turbidity_rep1, Turbidity_rep2, Turbidity_rep3), na.rm = TRUE),
  # add in error for each variable 
  Salinity_error = sd(Salinity, na.rm = TRUE),
         Temperature_error = sd(Temperature, na.rm = TRUE),
         DissolvedOxygen_error = sd(DissolvedOxygen, na.rm = TRUE),
         Turbidity_error = sd(c(Turbidity_rep1, Turbidity_rep2, Turbidity_rep3), na.rm = TRUE)) %>%
  ungroup()
# not getting error for anything except turbidity, will look at this later 
```

```{r}
# I just want to take a quick look at the seine data to see how many unique taxa we have 
unique_taxa <- kb_seine %>%
  dplyr::select(ScientificName) %>%
  distinct()
# alright so we have 27 unique taxa in the seine data 
# let's look at how many belong to the April samples and the September samples 
april_taxa <- seine %>%
  filter(SamplingPeriod == 1 & SamplingYear == 2022) %>%
  dplyr::select(ScientificName) %>%
  distinct()
# 16 unique taxa in april 
september_taxa <- seine %>%
  filter(SamplingPeriod == 6 & SamplingYear == 2022) %>%
  dplyr::select(ScientificName) %>%
  distinct()
# 26 unique taxa in september
# which were the taxa that were only found in september? and those that were only found in april? 
unique_september_taxa <- september_taxa %>%
  anti_join(april_taxa, by = "ScientificName")
print(unique_september_taxa) # 15 unique taxa to september 
unique_april_taxa <- april_taxa %>%
  anti_join(september_taxa, by = "ScientificName") # 5 unique taxa to april 
print(unique_april_taxa)
# so we have 5 unique taxa to april and 15 unique taxa to september, and 11 taxa that are shared between the two months. Let's print out the 11 that are shared 
shared_taxa <- april_taxa %>%
  inner_join(september_taxa, by = "ScientificName")
print(shared_taxa)

# it is important to note that these are taxa and not species, in the seine data we have varying taxonomic levels, we can make a taxonomic classification for each of these taxa to see what level they were classified down to. I have to figure out how to join the seine data with the taxonomy data to do this. This might just be easiest to do manually, I am going to write out the unique taxa and then classify them manually. 
write.csv(unique_taxa, "/Users/marisgoodwin/Documents/GITHUB/AMSS_2025/outputs/seine_unique_taxa.csv")

# read in the unique taxa with the classification
unique_taxa_class <- read.csv("/Users/marisgoodwin/Documents/GITHUB/AMSS_2025/inputs/seine/seine_unique_taxa_taxonomic_breakdown.csv")
# just a quick breakdown, of the unique taxa, how many were classified to the species level, genus level, family level, order level, class level, and phylum level. Let's first define the taxonomic level, this will be the column in the unique taxa class that has the classification. The order of rank is domain, kingdom, phylum, class, order, family, genus, species. I'll have R Read through each of the rows and classify the taxonomic level. If there is an NA it will write the column name in the taxonomic level column. If it goes all the way to species then it will write species in the taxonomic level column.
unique_taxa_class$TaxonomicLevel <- NA
for (i in 1:nrow(unique_taxa_class)){
  if (!is.na(unique_taxa_class$Species[i])){
    unique_taxa_class$TaxonomicLevel[i] <- "Species"
  } else if (!is.na(unique_taxa_class$Genus[i])){
    unique_taxa_class$TaxonomicLevel[i] <- "Genus"
  } else if (!is.na(unique_taxa_class$Family[i])){
    unique_taxa_class$TaxonomicLevel[i] <- "Family"
  } else if (!is.na(unique_taxa_class$Order[i])){
    unique_taxa_class$TaxonomicLevel[i] <- "Order"
  } else if (!is.na(unique_taxa_class$Class[i])){
    unique_taxa_class$TaxonomicLevel[i] <- "Class"
  } else if (!is.na(unique_taxa_class$Phylum[i])){
    unique_taxa_class$TaxonomicLevel[i] <- "Phylum"
  } else {
    unique_taxa_class$TaxonomicLevel[i] <- "NA"
  }
}

unique_taxa_class %>%
  group_by(TaxonomicLevel) %>%
  summarise(n = n())
# so for our 27 unique taxa, we have 23 identified down to the species level, 1 to the genus level, and three to the family level. 

# let's look at the unique taxa that were only found in september, what taxonomic level were they classified to?

unique_september_taxa_class <- unique_taxa_class %>%
  filter(ScientificName %in% unique_september_taxa$ScientificName)
print(unique_september_taxa_class)

unique_september_taxa_class %>%
  group_by(TaxonomicLevel) %>%
  summarise(n = n())
# 10 to species and 2 to family 
# now april 
unique_april_taxa_class <- unique_taxa_class %>%
  filter(ScientificName %in% unique_april_taxa$ScientificName)
print(unique_april_taxa_class)

unique_april_taxa_class %>%
  group_by(TaxonomicLevel) %>%
  summarise(n = n())
# three to species and 1 to family 

# let's plot out the taxonomy now for april and september at each site from our standardized data. 
# first we need to join the wisconsin data with the kb_seine data to get the taxonomy for each site

```

```{r}
# let's do bray curtis dissimilarity and plot the results
# first we need to make a distance matrix
dist <- vegdist(wisconsin, method = "bray")

# now we can do a non-metric multidimensional scaling
nmds <- metaMDS(dist, k = 2, distance = "bray")

nmds_coords <- as.data.frame(nmds$points)
nmds_coords$SampleID <- site_by_species$SampleID # I had to do some fenagling for this, it will not run on its own until I fix the code above from deleting the sampleID column/rownames of the site_by species matrix

# add in a variable called Sampling Month which identifies the SampleID with the SamplingMonth. for example if the SampleID is jn_1 then the SamplingMonth is April
nmds_coords$SamplingMonth <- ifelse(str_detect(nmds_coords$SampleID, "1"), "April", "September")
# and site is the site acronym that comes before the underscore in the SampleID
nmds_coords$site <- str_extract(nmds_coords$SampleID, "^[^_]+")
# now we can plot the samples with ggplot by Sample ID
ggplot(nmds_coords, aes(x = MDS1, y = MDS2, color = SamplingMonth, shape = site)) +
  geom_point() +
  theme_minimal() +
  labs(title = "NMDS of Fish Community Data from Kachemak Bay 2022",
       x = "NMDS1",
       y = "NMDS2",
       color = "Sampling Month",
       shape = "Site")
ggsave("/Users/marisgoodwin/Documents/GITHUB/AMSS_2025/outputs/seine_NMDS_plot.png")

# Euclidean distance matrix
euclidean_dist <- dist(kb_env[,3:6], method = "euclidean")
# Mantel test
seine_mantel_test <- ecodist::mantel(dist ~ euclidean_dist)
print(seine_mantel_test)

# Correlation Coefficient (mantelr): The very low value (0.0083) indicates a very weak relationship between the biological and environmental distance matrices. P-values (pval1, pval2, pval3): All p-values are high (greater than 0.05), indicating that the observed correlation is not statistically significant. This means that there is no strong evidence to suggest a meaningful relationship between the two matrices.Confidence Interval (llim.2.5%, ulim.97.5%): The confidence interval includes zero, reinforcing the conclusion that the correlation is not significant. the Mantel test results suggest that there is no significant correlation between the biological community structure and the environmental variables in your data.

# PERMANOVA
permanova_test <- adonis2(wisconsin ~ SamplingMonth + site_id, data = kb_env, method = "bray")
print(permanova_test)

# this show that there is a significant difference in the fish community structure between the two sampling months, but not between the sites.


# okay, so I have averaged by site id and sampling month which is making it harder to interpret relationships between environmental variables and biological data. We do have multiple seines from a given site, so this is a way that we can add in a random effect to the model to account for this. this would  include a random effect for site in the analysis to account for the nested structure of the data.
permanova_test <- adonis2(wisconsin ~ SamplingMonth + Temperature + Salinity + Turbidity + DissolvedOxygen + (1|site_id), data = kb_env, method = "bray")

print(permanova_test)
```

Let's plot out the seine taxonomy data. 
```{r}
# we will use the wisconsin standardized data to plot out the taxonomy for each site 
# first we need to join the wisconsin data with the kb_seine data to get the taxonomy for each site
rownames(wisconsin) <- site_by_species$SampleID

```

